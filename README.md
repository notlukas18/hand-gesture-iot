# âœ‹ðŸ¤– Hand Gesture Controlled IoT System

**ESP32 + Python + OpenCV + MediaPipe + MQTT**

This final-year project showcases a **smart, contactless interface** that enables users to control multiple LEDs using hand gestures. Leveraging **Computer Vision** and **IoT**, it offers a modern, accessible, and touchless control solution for smart environments and home automation.

---

## ðŸš€ Key Features

* ðŸ–ï¸ **Real-time hand gesture recognition** using MediaPipe
* ðŸ’¡ **Individual control** of five LEDs (Thumb, Index, Middle, Ring, Pinky)
* ðŸ”„ **Universal gestures** to toggle all LEDs ON/OFF
* ðŸŒ **MQTT communication** between Python client and ESP32
* ðŸ§± Modular, scalable design for future **smart home integration**

---

## ðŸ–¼ï¸ Demo Preview

![Demo Screenshot](https://github.com/user-attachments/assets/a1754ec2-0746-4499-9113-327430af8fe0)

---

## ðŸ§  System Overview

1. A **webcam** captures the live video stream
2. **MediaPipe** detects hand landmarks in real time
3. A **Python script** processes gestures and sends MQTT messages
4. The **ESP32** microcontroller receives the messages and toggles LEDs accordingly

---

## ðŸ› ï¸ Tech Stack

* **Python 3.11+**
* **MediaPipe & OpenCV** for gesture detection
* **ESP32** programmed via **Arduino IDE**
* **MQTT** protocol with **Mosquitto broker**
* **Fritzing** for circuit design and wiring diagrams

---

## ðŸ–¥ï¸ Getting Started

### 1. Python Client (Computer Side)

Install the required dependencies:

```bash
pip install opencv-python mediapipe paho-mqtt
```

Edit the `gesture_control_mqtt.py` file to specify your MQTT broker IP:

```python
MQTT_BROKER = "your_broker_ip"
```

Run the script:

```bash
python gesture_control_mqtt.py
```

---

### 2. MQTT Broker Setup

You can install Mosquitto locally or on a cloud-based virtual machine:

```bash
sudo apt install mosquitto mosquitto-clients
sudo systemctl start mosquitto
```

---

## âœ‹ Supported Hand Gestures

| Gesture          | Action                 |
| ---------------- | ---------------------- |
| All fingers up   | Turn **ALL LEDs ON**   |
| All fingers down | Turn **ALL LEDs OFF**  |
| Thumb only up    | Turn ON **Yellow LED** |
| Index only up    | Turn ON **Red LED**    |
| Middle only up   | Turn ON **Green LED**  |
| Ring only up     | Turn ON **Blue LED**   |
| Pinky only up    | Turn ON **White LED**  |

---

## ðŸ“ˆ Future Enhancements

* ðŸŽ™ï¸ Add **voice command** functionality
* âœ‹ Enable **multi-hand gesture** recognition
* ðŸ“± Build a **mobile app** for remote access
* ðŸ  Integrate with platforms like **Home Assistant** or **Google Home**

---

## ðŸ”’ Ethical & Social Impact

* ðŸ“· All video processing is performed **locally** â€” ensuring **user privacy**
* â™¿ Highly beneficial for users with **mobility or speech impairments**
* âš¡ Uses an **energy-efficient ESP32** for minimal power consumption
* ðŸŒ Designed to be **inclusive, adaptable**, and globally applicable

---

## ðŸ§¾ License

This project is licensed under the [MIT License](LICENSE).

---

## ðŸ¤ Contributing

We welcome pull requests!
If you'd like to improve gesture recognition, expand hardware compatibility, or enhance the interface, feel free to fork the repo and contribute.

---

## ðŸ‘¥ Authors

* **Abduvahhobov Javohir** â€“ Software Development (Python, OpenCV, MQTT)
* **Mansurxojayev Xojiakbar** â€“ Hardware Design (ESP32, Circuit Wiring)

> Final Year Project â€” IoT Internship
> Tashkent Turin Polytechnic University

